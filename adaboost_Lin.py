# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1keaIq3ltH91qIIYqiOhy2kW3WjRkcf85

two hot encoding: convert files into ML input
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
# %matplotlib inline 
import os
from google.colab import drive
drive.mount('/content/drive')

root_path = 'drive/My Drive/bioinformatics_hackathon'  #change dir to your project folder
os.chdir(root_path)
os.getcwd()

import pandas as pd
single=pd.read_csv('single_muts_train.csv')
multiple=pd.read_csv('multiple_muts_train.csv')

!pip install biopython

import Bio.PDB 

def onehot_encode_aa(sequence):
  aa_indices = []
  for aa in sequence:
    try:
      aa_index = Bio.PDB.Polypeptide.one_to_index(aa)
    except:
      aa_index = 20
    aa_indices.append(aa_index)
  sequence_onehot=np.zeros((len(aa_indices), 21))
  sequence_onehot[np.arange(len(aa_indices)), aa_indices]=1
  return sequence_onehot

def code_index_convert(code):
  if code=="T":
    secondary_index=2
  if code=="H":
    secondary_index=0
  if code=="E":
    secondary_index=1
  return secondary_index

def twohot_encode_aa(secondary_structure):
  secondary_indices = []
  for code in secondary_structure:
    secondary_index=code_index_convert(code)
    secondary_indices.append(secondary_index)
  sequence_twohot=np.zeros((len(secondary_indices), 3))
  sequence_twohot[np.arange(len(secondary_indices)), secondary_indices]=1
  return sequence_twohot

single_sequences_onehot=[]
for sequence in single['sequence']:
  single_sequence_onehot=onehot_encode_aa(sequence)
  single_sequences_onehot.append(single_sequence_onehot)

single_sequences_twohot=[]
for secondary_structure in single['secondary_structure']:
  single_sequence_twohot=twohot_encode_aa(secondary_structure)
  single_sequences_twohot.append(single_sequence_twohot)
single_sequences_input=np.c_[np.array(single_sequences_onehot),np.array(single_sequences_twohot)]

single_input = single_sequences_input.reshape(single_sequences_input.shape[0], single_sequences_input.shape[1]*single_sequences_input.shape[2])

multiple_sequences_onehot=[]
for sequence in multiple['sequence']:
  multiple_sequence_onehot=onehot_encode_aa(sequence)
  multiple_sequences_onehot.append(multiple_sequence_onehot)

multiple_sequences_twohot=[]
for secondary_structure in multiple['secondary_structure']:
  multiple_sequence_twohot=twohot_encode_aa(secondary_structure)
  multiple_sequences_twohot.append(multiple_sequence_twohot)

multiple_sequences_input=np.c_[np.array(multiple_sequences_onehot),np.array(multiple_sequences_twohot)]

multiple_input = multiple_sequences_input.reshape(multiple_sequences_input.shape[0], multiple_sequences_input.shape[1]*multiple_sequences_input.shape[2])

pd.DataFrame(multiple_input).to_csv("multiple_input.csv")

pd.DataFrame(single_input).to_csv("single_input.csv")

"""combine training data, start Adaboost model training"""

twohot_single = pd.read_csv("twohot_single.csv")
twohot_multi = pd.read_csv("twohot_multi.csv")

twohot_input = pd.concat([twohot_single, twohot_multi]) 
final_twohot_input = twohot_input.dropna(axis=0,how='any')

Xtrain = final_twohot_input.iloc[:,1:1033]
Ytrain = final_twohot_input.iloc[:,1033]

from sklearn.ensemble import AdaBoostRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
regr = AdaBoostRegressor(random_state=0, n_estimators=50)
#original model
score_mse = cross_val_score(regr, Xtrain, Ytrain, cv=5, scoring = "neg_mean_squared_error").mean()  #scoring - r2
print(score_mse)

#parameter update
from sklearn.model_selection import GridSearchCV

tuned_parameters = [{'n_estimators':[30,50,70],
                     'learning_rate':[0.1,0.25,0.5,0.7,1]
                     }]


grid = GridSearchCV(AdaBoostRegressor(random_state=0), 
                    tuned_parameters, scoring= "neg_mean_squared_error", cv = 5)
grid.fit(Xtrain, Ytrain)
print("The best parameters are %s with a score of %f" % (grid.best_params_,grid.best_score_))

#CV grid-search (print all results)
means = grid.cv_results_['mean_test_score']
stds = grid.cv_results_['std_test_score']
for mean, std, params in zip(means, stds, grid.cv_results_['params']):
  print("%f (+/-%0.03f) for %r" % (mean, std * 2, params))

tuned_parameters2 = [{'n_estimators':[50,55,60],
                     'learning_rate':[0.2,0.22,0.25,0.28,0.3]
                     }]


grid2 = GridSearchCV(AdaBoostRegressor(random_state=0), #需要替换model
                    tuned_parameters2, scoring= "neg_mean_squared_error", cv = 5)
grid2.fit(Xtrain, Ytrain)

means = grid2.cv_results_['mean_test_score']
stds = grid2.cv_results_['std_test_score']
for mean, std, params in zip(means, stds, grid2.cv_results_['params']):
  print("%f (+/-%0.03f) for %r" % (mean, std * 2, params))

"""Test result"""

single_test_input = pd.read_csv("twohot_single_test.csv")
Xtest_single = single_test_input.iloc[:,1:1033]
Ytest_single = single_test_input.iloc[:,1033]

from sklearn.ensemble import AdaBoostRegressor
regr_single = AdaBoostRegressor(random_state=0, n_estimators=55, learning_rate=0.25)
regr_single.fit(Xtrain, Ytrain)
Ypred_single = regr_single.predict(Xtest_single)

plt.scatter(Ypred_single,Ytest_single)
plt.xlabel("y_pred")
plt.ylabel("y_true")
plt.xlim(-1.5,2)

df = pd.concat([Ytest_single, pd.DataFrame(Ypred_single)], axis=1)
df.corr()

###mse
np.sum((Y_single_output.iloc[:,0]-Y_single_output.iloc[:,1])**2)/len(Ytest_single)

Y_single_output=pd.DataFrame()
Y_single_output["Adaboost"] = Ypred_single
Y_single_output["stabilityscore"] = single_test_input["stabilityscore"]
Y_single_output.index = single_test_input["name"]
Y_single_output.to_csv("single_test_output.csv")

from sklearn.ensemble import AdaBoostRegressor
multiple_test_input = pd.read_csv("twohot_multi_test.csv")

Xtest_multiple = multiple_test_input.iloc[:,1:1033]
Ytest_multiple = multiple_test_input.iloc[:,1033]
regr_multiple = AdaBoostRegressor(random_state=1, n_estimators=55, learning_rate=0.25)
regr_multiple.fit(Xtrain, Ytrain)
Ypred_multiple = regr_multiple.predict(Xtest_multiple)

Y_multiple_output=pd.DataFrame()
Y_multiple_output["Adaboost"] = Ypred_multiple
Y_multiple_output["stabilityscore"] = multiple_test_input["stabilityscore"]
Y_multiple_output.index = multiple_test_input["name"]
Y_multiple_output.dropna(how="any", axis=0)
Y_multiple_output.to_csv("multiple_test_output.csv")

plt.scatter(Y_multiple_output.iloc[:,0],Y_multiple_output.iloc[:,1])
plt.xlabel("y_pred")
plt.ylabel("y_true")
plt.xlim(-1.5,2)

df_multi = pd.concat([Y_multiple_output.iloc[:,0], Y_multiple_output.iloc[:,1]], axis=1)
df_multi.corr()

###mse
np.sum((Y_multiple_output.iloc[:,0]-Y_multiple_output.iloc[:,1])**2)/len(Ypred_multiple)
